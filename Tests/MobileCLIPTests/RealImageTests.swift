import Testing
import Foundation
import MLX
import MLXLMCommon
import CoreGraphics
import AppKit
@testable import MobileCLIP

// MARK: - Real Image Tests

@Suite("Real Image Tests")
struct RealImageTests {

    // MARK: - Helper Functions

    /// ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’MLXArrayã«å¤‰æ›
    /// - Parameter imagePath: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    /// - Returns: MLXArray in NCHW format [1, 3, 224, 224]
    static func loadImage(from imagePath: String) throws -> MLXArray {
        guard let nsImage = NSImage(contentsOfFile: imagePath) else {
            throw NSError(domain: "RealImageTests", code: 1, userInfo: [NSLocalizedDescriptionKey: "Failed to load image from \(imagePath)"])
        }

        // NSImageã‚’CGImageã«å¤‰æ›
        guard let cgImage = nsImage.cgImage(forProposedRect: nil, context: nil, hints: nil) else {
            throw NSError(domain: "RealImageTests", code: 2, userInfo: [NSLocalizedDescriptionKey: "Failed to convert NSImage to CGImage"])
        }

        // 224x224ã«ãƒªã‚µã‚¤ã‚º
        let targetSize = CGSize(width: 224, height: 224)
        guard let resizedImage = resizeImage(cgImage, to: targetSize) else {
            throw NSError(domain: "RealImageTests", code: 3, userInfo: [NSLocalizedDescriptionKey: "Failed to resize image"])
        }

        // CGImageã‹ã‚‰ãƒ”ã‚¯ã‚»ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
        let width = 224
        let height = 224
        let bytesPerPixel = 4
        let bytesPerRow = bytesPerPixel * width
        let bitsPerComponent = 8

        var pixelData = [UInt8](repeating: 0, count: width * height * bytesPerPixel)

        let colorSpace = CGColorSpaceCreateDeviceRGB()
        let context = CGContext(
            data: &pixelData,
            width: width,
            height: height,
            bitsPerComponent: bitsPerComponent,
            bytesPerRow: bytesPerRow,
            space: colorSpace,
            bitmapInfo: CGImageAlphaInfo.premultipliedLast.rawValue
        )

        context?.draw(resizedImage, in: CGRect(x: 0, y: 0, width: width, height: height))

        // [0-255] UInt8 â†’ [0-1] Float ã«æ­£è¦åŒ–ã—ã€ImageNetçµ±è¨ˆã§æ¨™æº–åŒ–
        let mean: [Float] = [0.485, 0.456, 0.406]
        let std: [Float] = [0.229, 0.224, 0.225]

        var imageArray = [Float](repeating: 0, count: 3 * height * width)

        for y in 0..<height {
            for x in 0..<width {
                let pixelIndex = y * width + x
                let dataIndex = pixelIndex * bytesPerPixel

                let r = Float(pixelData[dataIndex]) / 255.0
                let g = Float(pixelData[dataIndex + 1]) / 255.0
                let b = Float(pixelData[dataIndex + 2]) / 255.0

                // NCHW format: [channels, height, width]
                imageArray[0 * height * width + pixelIndex] = (r - mean[0]) / std[0]
                imageArray[1 * height * width + pixelIndex] = (g - mean[1]) / std[1]
                imageArray[2 * height * width + pixelIndex] = (b - mean[2]) / std[2]
            }
        }

        // MLXArrayä½œæˆ: [1, 3, 224, 224]
        let mlxArray = MLXArray(imageArray, [1, 3, height, width])
        return mlxArray
    }

    /// CGImageã‚’ãƒªã‚µã‚¤ã‚º
    private static func resizeImage(_ image: CGImage, to size: CGSize) -> CGImage? {
        let width = Int(size.width)
        let height = Int(size.height)

        let colorSpace = CGColorSpaceCreateDeviceRGB()
        let bitmapInfo = CGBitmapInfo(rawValue: CGImageAlphaInfo.premultipliedLast.rawValue)

        guard let context = CGContext(
            data: nil,
            width: width,
            height: height,
            bitsPerComponent: 8,
            bytesPerRow: 4 * width,
            space: colorSpace,
            bitmapInfo: bitmapInfo.rawValue
        ) else {
            return nil
        }

        context.interpolationQuality = .high
        context.draw(image, in: CGRect(x: 0, y: 0, width: width, height: height))

        return context.makeImage()
    }

    // MARK: - Helper to get test image path

    /// Bundleã‹ã‚‰ãƒ†ã‚¹ãƒˆç”»åƒã®ãƒ‘ã‚¹ã‚’å–å¾—
    static func getTestImagePath(filename: String = "test_image.jpg") -> String? {
        // Bundle.moduleã®ãƒªã‚½ãƒ¼ã‚¹URLã‚’å–å¾—
        guard let bundleResourceURL = Bundle.module.resourceURL else {
            return nil
        }

        // ã¾ãšç›´æ¥ç¢ºèª
        var url = bundleResourceURL.appendingPathComponent(filename)

        // è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ Resources/ ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è©¦ã™
        if !FileManager.default.fileExists(atPath: url.path) {
            url = bundleResourceURL.appendingPathComponent("Resources").appendingPathComponent(filename)
        }

        // å­˜åœ¨ã‚’ç¢ºèª
        guard FileManager.default.fileExists(atPath: url.path) else {
            return nil
        }

        return url.path
    }

    // MARK: - Tests with Real Images

    @Test("Encode real image from file")
    func encodeRealImage() async throws {
        // Bundleã‹ã‚‰ãƒ†ã‚¹ãƒˆç”»åƒã®ãƒ‘ã‚¹ã‚’å–å¾—
        guard let testImagePath = Self.getTestImagePath() else {
            print("âš ï¸ Test image not found in bundle")
            print("   Please add 'test_image.jpg' to Tests/MobileCLIP2Tests/Resources/")
            return  // ãƒ†ã‚¹ãƒˆç”»åƒãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        }

        let model = MobileCLIP()
        try await model.load(configuration: ModelConfiguration(id: "1amageek/MobileCLIP2-S4"))

        let imageArray = try Self.loadImage(from: testImagePath)
        print("âœ… Loaded image: \(imageArray.shape)")

        let embedding = try model.encodeImage(imageArray)
        print("âœ… Image embedding: \(embedding.shape)")

        #expect(embedding.shape[0] == 1, "Batch size should be 1")
        #expect(embedding.shape[1] == 768, "Embedding dimension should be 768")

        // L2æ­£è¦åŒ–ã®ç¢ºèª
        let norm = embedding.square().sum(axis: -1).sqrt()
        let normValue = norm.item(Float.self)
        #expect(abs(normValue - 1.0) < 0.01, "Embedding should be L2 normalized")

        print("âœ… Embedding norm: \(normValue)")
    }

    @Test("Real image-text similarity")
    func realImageTextSimilarity() async throws {
        // Bundleã‹ã‚‰ãƒ†ã‚¹ãƒˆç”»åƒã®ãƒ‘ã‚¹ã‚’å–å¾—
        guard let testImagePath = Self.getTestImagePath() else {
            print("âš ï¸ Test image not found in bundle")
            print("   Please add 'test_image.jpg' to Tests/MobileCLIP2Tests/Resources/")
            return
        }

        let model = MobileCLIP()
        try await model.load(configuration: ModelConfiguration(id: "1amageek/MobileCLIP2-S4"))

        // ç”»åƒã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        let imageArray = try Self.loadImage(from: testImagePath)
        let imageEmbedding = try model.encodeImage(imageArray)

        // è¤‡æ•°ã®ãƒ†ã‚­ã‚¹ãƒˆã¨ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—
        let texts = [
            "a photo of a cat",
            "a photo of a dog",
            "a photo of a bird",
            "a photo of a car",
            "a photo of a flower"
        ]

        let tokenizer = try Tokenizer()
        var similarities = [Float]()

        for text in texts {
            let tokens = tokenizer.encode(text)
            let textEmbedding = try model.encodeText(tokens)
            let similarity = model.computeSimilarity(
                imageEmbedding: imageEmbedding,
                textEmbedding: textEmbedding
            )
            similarities.append(similarity)
        }

        print("âœ… Image-Text Similarities:")
        for (i, text) in texts.enumerated() {
            print("   \(text): \(similarities[i])")
        }

        // ã™ã¹ã¦ã®é¡ä¼¼åº¦ãŒæœ‰åŠ¹ãªç¯„å›²å†…ã«ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        for similarity in similarities {
            #expect(similarity >= -1.0 && similarity <= 1.0, "Similarity should be in [-1, 1]")
            #expect(!similarity.isNaN, "Similarity should not be NaN")
        }
    }

    @Test("Zero-shot classification with real image")
    func zeroShotClassificationRealImage() async throws {
        // Bundleã‹ã‚‰ãƒ†ã‚¹ãƒˆç”»åƒã®ãƒ‘ã‚¹ã‚’å–å¾—
        guard let testImagePath = Self.getTestImagePath() else {
            print("âš ï¸ Test image not found in bundle")
            print("   Please add 'test_image.jpg' to Tests/MobileCLIP2Tests/Resources/")
            return
        }

        let model = MobileCLIP()
        try await model.load(configuration: ModelConfiguration(id: "1amageek/MobileCLIP2-S4"))

        // ç”»åƒã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        let imageArray = try Self.loadImage(from: testImagePath)
        let imageEmbedding = try model.encodeImage(imageArray)

        // åˆ†é¡ç”¨ã®ãƒ©ãƒ™ãƒ«
        let labels = [
            "a photo of a cat",
            "a photo of a dog",
            "a photo of a bird"
        ]

        let tokenizer = try Tokenizer()
        var logits = [Float]()

        // å„ãƒ©ãƒ™ãƒ«ã¨ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—
        for label in labels {
            let tokens = tokenizer.encode(label)
            let textEmbedding = try model.encodeText(tokens)
            let similarity = model.computeSimilarity(
                imageEmbedding: imageEmbedding,
                textEmbedding: textEmbedding
            )
            logits.append(similarity)
        }

        // Softmaxé©ç”¨
        let maxLogit = logits.max() ?? 0
        let expLogits = logits.map { exp($0 - maxLogit) }
        let sumExp = expLogits.reduce(0, +)
        let probabilities = expLogits.map { $0 / sumExp }

        print("âœ… Zero-shot Classification:")
        for (i, label) in labels.enumerated() {
            print("   \(label): \(probabilities[i] * 100)%")
        }

        // æœ€ã‚‚ç¢ºç‡ãŒé«˜ã„ãƒ©ãƒ™ãƒ«ã‚’å–å¾—
        if let maxIndex = probabilities.indices.max(by: { probabilities[$0] < probabilities[$1] }) {
            print("   Predicted: \(labels[maxIndex]) (\(probabilities[maxIndex] * 100)%)")
        }

        // ç¢ºç‡ã®åˆè¨ˆãŒ1ã«è¿‘ã„ã“ã¨ã‚’ç¢ºèª
        let sumProb = probabilities.reduce(0, +)
        #expect(abs(sumProb - 1.0) < 0.01, "Probabilities should sum to 1.0")
    }
}

// MARK: - Download Test Image Helper

@Suite("Test Image Setup")
struct TestImageSetup {

    @Test("Instructions for adding test images", .disabled("Information only"))
    func testImageInstructions() {
        print("""

        ğŸ“¸ ãƒ†ã‚¹ãƒˆç”»åƒã®æº–å‚™æ–¹æ³•:

        1. ãƒ†ã‚¹ãƒˆç”¨ã®ç”»åƒã‚’ç”¨æ„ã—ã¦ãã ã•ã„ï¼ˆJPEG, PNGå½¢å¼ï¼‰

        2. ä»¥ä¸‹ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç”»åƒã‚’é…ç½®ã—ã¦ãã ã•ã„:
           /Users/1amageek/Desktop/CLIP/MobileCLIP2App/Tests/MobileCLIP2Tests/Resources/

        3. ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ä»¥ä¸‹ã®ã„ãšã‚Œã‹ã«ã—ã¦ãã ã•ã„:
           - test_image.jpg
           - test_cat.jpg (çŒ«ã®ç”»åƒ)
           - test_dog.jpg (çŠ¬ã®ç”»åƒ)

        4. Xcodeã§ Package.swift ã‚’æ›´æ–°ã—ã¦ã€ãƒªã‚½ãƒ¼ã‚¹ã‚’å«ã‚ã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„:

           .testTarget(
               name: "MobileCLIP2Tests",
               dependencies: ["MobileCLIP2"],
               resources: [.copy("Resources")]
           )

        5. ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„

        ã¾ãŸã¯ã€ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‹ã‚‰ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰:

        # Resourcesãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        mkdir -p Tests/MobileCLIP2Tests/Resources

        # ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆä¾‹ï¼‰
        curl -o Tests/MobileCLIP2Tests/Resources/test_cat.jpg \\
          https://placekitten.com/224/224

        """)
    }
}
