import Foundation
import MLX

/// Memory profile for GPU cache configuration
///
/// Selects optimal GPU cache size based on device memory capacity
public enum MemoryProfile {
    /// Low memory devices (20MB)
    /// - For iPhone SE, older iPads, memory-constrained devices
    case low

    /// Balanced configuration (64MB) - Default
    /// - Recommended for most devices
    case balanced

    /// High-performance devices (128MB)
    /// - For M1/M2 Macs, iPad Pro, devices with ample memory
    case high

    /// Custom configuration
    /// - Parameter megabytes: Cache size in megabytes
    case custom(megabytes: Int)

    var bytes: Int {
        switch self {
        case .low:
            return 20 * 1024 * 1024
        case .balanced:
            return 64 * 1024 * 1024
        case .high:
            return 128 * 1024 * 1024
        case .custom(let megabytes):
            return megabytes * 1024 * 1024
        }
    }
}

/// MobileCLIP2-S4 Model
///
/// CLIP model for encoding images and text to compute similarity
public class MobileCLIP2 {

    private let loader: ModelLoader
    private var visionEncoder: VisionEncoderComplete?
    private var textEncoder: TextEncoder?

    /// Initialize MobileCLIP2 model
    /// - Parameter memoryProfile: Memory profile (default: .balanced)
    ///
    /// Usage examples:
    /// ```swift
    /// // Default (64MB)
    /// let model = MobileCLIP2()
    ///
    /// // Memory-constrained devices (20MB)
    /// let model = MobileCLIP2(memoryProfile: .low)
    ///
    /// // High-performance devices (128MB)
    /// let model = MobileCLIP2(memoryProfile: .high)
    ///
    /// // Custom configuration (100MB)
    /// let model = MobileCLIP2(memoryProfile: .custom(megabytes: 100))
    /// ```
    public init(memoryProfile: MemoryProfile = .balanced) {
        self.loader = ModelLoader()

        // Set GPU cache limit for optimal performance
        // This prevents out-of-memory issues and improves inference speed
        MLX.GPU.set(cacheLimit: memoryProfile.bytes)
    }

    // MARK: - Model Loading (Synchronous)

    /// ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
    /// - Parameter basePath: ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹
    public func loadModel(from basePath: String) throws {
        try loader.loadWeights(basePath: basePath)
        try initializeEncoders()
    }

    /// Bundleã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
    /// - Parameter resourceName: ãƒªã‚½ãƒ¼ã‚¹åï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: "MobileCLIP2-S4"ï¼‰
    public func loadModelFromBundle(resourceName: String = "MobileCLIP2-S4") throws {
        try loader.loadFromBundle(resourceName: resourceName)
        try initializeEncoders()
    }

    // MARK: - Model Loading (Asynchronous)

    /// ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’éåŒæœŸãƒ­ãƒ¼ãƒ‰
    /// UIãƒ–ãƒ­ãƒƒã‚¯ã‚’é˜²ããŸã‚ã€ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã‚’åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œ
    /// - Parameter basePath: ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹
    ///
    /// Usage:
    /// ```swift
    /// let model = MobileCLIP2()
    /// try await model.loadModelAsync(from: "/path/to/model")
    /// ```
    public func loadModelAsync(from basePath: String) async throws {
        // Load on background thread
        try await withCheckedThrowingContinuation { (continuation: CheckedContinuation<Void, Error>) in
            DispatchQueue.global(qos: .userInitiated).async { [weak self] in
                guard let self = self else {
                    continuation.resume(throwing: ModelError.invalidModelStructure)
                    return
                }
                do {
                    try self.loader.loadWeights(basePath: basePath)
                    try self.initializeEncoders()
                    continuation.resume()
                } catch {
                    continuation.resume(throwing: error)
                }
            }
        }
    }

    /// Bundleã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’éåŒæœŸãƒ­ãƒ¼ãƒ‰
    /// UIãƒ–ãƒ­ãƒƒã‚¯ã‚’é˜²ããŸã‚ã€ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã‚’åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œ
    /// - Parameter resourceName: ãƒªã‚½ãƒ¼ã‚¹åï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: "MobileCLIP2-S4"ï¼‰
    ///
    /// Usage:
    /// ```swift
    /// let model = MobileCLIP2()
    /// try await model.loadModelFromBundleAsync()
    /// ```
    public func loadModelFromBundleAsync(resourceName: String = "MobileCLIP2-S4") async throws {
        // Load on background thread
        try await withCheckedThrowingContinuation { (continuation: CheckedContinuation<Void, Error>) in
            DispatchQueue.global(qos: .userInitiated).async { [weak self] in
                guard let self = self else {
                    continuation.resume(throwing: ModelError.invalidModelStructure)
                    return
                }
                do {
                    try self.loader.loadFromBundle(resourceName: resourceName)
                    try self.initializeEncoders()
                    continuation.resume()
                } catch {
                    continuation.resume(throwing: error)
                }
            }
        }
    }

    private func initializeEncoders() throws {
        // Vision Encoderã‚’åˆæœŸåŒ–
        visionEncoder = VisionEncoderComplete(weights: loader.weights)

        // Text Encoderã‚’åˆæœŸåŒ–
        textEncoder = TextEncoder(weights: loader.weights)
    }

    // MARK: - Warmup

    /// Warm up the model by running a single inference pass
    /// This compiles Metal kernels ahead of time, improving subsequent inference speed
    /// Call this after loading the model to avoid slow first inference
    public func warmup() throws {
        guard visionEncoder != nil, textEncoder != nil else {
            throw ModelError.invalidModelStructure
        }

        // Warm up vision encoder with dummy input
        let dummyImage = MLXArray.ones([1, 3, 224, 224]) * 0.5
        _ = try encodeImage(dummyImage)

        // Warm up text encoder with dummy input
        var dummyTokens = [Int32](repeating: 0, count: 77)
        dummyTokens[0] = 49406  // SOS
        dummyTokens[1] = 1000
        dummyTokens[2] = 49407  // EOS
        let tokenArray = MLXArray(dummyTokens).reshaped(1, 77)
        _ = try encodeText(tokenArray)
    }

    /// éåŒæœŸwarmup
    /// Metal kernelã®ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã‚’éåŒæœŸã§å®Ÿè¡Œ
    ///
    /// Usage:
    /// ```swift
    /// try await model.loadModelFromBundleAsync()
    /// try await model.warmupAsync()
    /// ```
    public func warmupAsync() async throws {
        // Warmup on background thread
        try await withCheckedThrowingContinuation { (continuation: CheckedContinuation<Void, Error>) in
            DispatchQueue.global(qos: .userInitiated).async { [weak self] in
                guard let self = self else {
                    continuation.resume(throwing: ModelError.invalidModelStructure)
                    return
                }
                do {
                    try self.warmup()
                    continuation.resume()
                } catch {
                    continuation.resume(throwing: error)
                }
            }
        }
    }

    // MARK: - Encoding

    /// ç”»åƒã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
    /// - Parameter image: [batch, channels, height, width] ã®ç”»åƒãƒ†ãƒ³ã‚½ãƒ«
    /// - Returns: [batch, embed_dim] ã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«
    public func encodeImage(_ image: MLXArray) throws -> MLXArray {
        guard let encoder = visionEncoder else {
            throw ModelError.invalidModelStructure
        }

        return try encoder.encode(image)
    }

    /// ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
    /// - Parameter tokens: [batch, context_length] ã®ãƒˆãƒ¼ã‚¯ãƒ³IDé…åˆ—
    /// - Returns: [batch, embed_dim] ã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«
    public func encodeText(_ tokens: MLXArray) throws -> MLXArray {
        guard let encoder = textEncoder else {
            throw ModelError.invalidModelStructure
        }

        return try encoder.encode(tokens)
    }

    // MARK: - Similarity

    /// ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆã®é¡ä¼¼åº¦ã‚’è¨ˆç®—
    /// - Parameters:
    ///   - imageEmbedding: ç”»åƒã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«
    ///   - textEmbedding: ãƒ†ã‚­ã‚¹ãƒˆã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«
    /// - Returns: ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦
    public func computeSimilarity(
        imageEmbedding: MLXArray,
        textEmbedding: MLXArray
    ) -> Float {
        // ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ = dot(A, B) / (||A|| * ||B||)
        // ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã¯æ—¢ã«L2æ­£è¦åŒ–æ¸ˆã¿ãªã®ã§ã€å˜ç´”ãªãƒ‰ãƒƒãƒˆç©ã§è¨ˆç®—å¯èƒ½
        // ãŸã ã—ã€å¿µã®ãŸã‚ãƒãƒ«ãƒ ã§æ­£è¦åŒ–

        let dotProduct = (imageEmbedding * textEmbedding).sum(axis: -1)

        // Force evaluation to ensure computation is complete
        eval(dotProduct)

        let similarity = dotProduct.item(Float.self)
        return similarity
    }

    // MARK: - Utility

    /// ãƒ¢ãƒ‡ãƒ«ã®çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
    public func printModelInfo() {
        print("\nğŸ“Š Model Information")
        print("   Total tensors: \(loader.weights.count)")

        // Vision encoder ã®é‡ã¿
        let visionWeights = loader.filterWeights(prefix: "module.visual")
        print("   Vision encoder tensors: \(visionWeights.count)")

        // Text encoder ã®é‡ã¿
        let textWeights = loader.filterWeights(prefix: "module.text")
        print("   Text encoder tensors: \(textWeights.count)")

        // Logit scale
        if let logitScale = loader.getWeight("module.logit_scale") {
            print("   Logit scale: \(logitScale.item(Float.self))")
        }
    }

    /// åˆ©ç”¨å¯èƒ½ãªé‡ã¿ã®ã‚­ãƒ¼ã‚’è¡¨ç¤º
    public func printAvailableKeys(limit: Int = 20) {
        print("\nğŸ“‹ Available weight keys (showing first \(limit)):")
        for (i, key) in loader.allKeys.prefix(limit).enumerated() {
            if let weight = loader.getWeight(key) {
                print("  \(i + 1). \(key): \(weight.shape)")
            }
        }

        if loader.allKeys.count > limit {
            print("  ... and \(loader.allKeys.count - limit) more")
        }
    }
}
